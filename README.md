Разработано веб-приложение, предназначенное для выполнения переводов текстов между различными языками с использованием LLM, развернутых через платформу Ollama.

Функциональные возможности:
* Возможность индитефикации исходного языка текста автоматически.
* Предусмотрены режимы перевода: формальный, разговорный, маркетинговый и технический.
* Переводы сохраняются в базе данных.
* Реализован просмотр истории выполненных переводов.

Инструкция по развертыванию:
* Установленные Docker и Docker Compose.
* Локально развернутый сервис Ollama.
Порядок запуска:
1. Запустите сервер Ollama: ollama serve 
2. Убедитесь в наличии языковой модели: ollama pull gemma2:2b 
3. Запустите приложение с помощью Docker Compose: bash docker-compose up --build 
4. Приложение будет доступно по адресу: http://localhost:8000.

Архитектура приложения: Основные компоненты системы включают:
* main.py — ядро приложения на FastAPI.
* llm_service.py — сервис для взаимодействия с LLM через Ollama.
* models.py — модели данных.
* database.py — модуль управления подключением к базе данных.
* config.py — конфигурационные параметры.

Основные эндпоинты:
* POST /translate — выполнение перевода.
* GET /history/translations — получение истории переводов.

Поддерживаемые языки и режимы:
* Языки: русский, английский, испанский, французский, немецкий, итальянский, китайский, японский, корейский, арабский, португальский.
* Стили перевода: разговорный стиль, формальный стиль, маркетинговый текст, технический текст
